{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                            Luis Ramirez Camargo, June 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up PV output data of the Chilean installations\n",
    "This notebook generates CSV files with the merged and clean time series of PV electricity generation for each large PV installation in Chile.\n",
    "See related notebooks: 2_get_time_series_from_era5_land_and_merra2_for_pv_calculation, 3_pv_output_from_ERA5_land_and_merra2 and 4_pv_validation_ERA5_land_MERRA2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import geopandas\n",
    "import glob\n",
    "from tkinter import Tcl\n",
    "import gc\n",
    "import unidecode\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "installations_chile_pre = \\\n",
    "Path(\"input_data/solares_fd0779de_0870_4194_b962_83a842d8c316.shp\")\n",
    "def clean_installations_locations(installations_chile_pre):\n",
    "    '''creates a data frame with the location and basic \n",
    "    characteristics of the large PV installations in Chile'''\n",
    "    pvs_chile = geopandas.read_file(installations_chile_pre)\n",
    "    pvs_chile_4326 = pvs_chile.to_crs(epsg=4326)\n",
    "    installations_list = pvs_chile_4326[\"NOMBRE\"]\n",
    "    installations_chile = pd.DataFrame({'latitude': pvs_chile_4326.geometry.y.values, \n",
    "                        'longitude': pvs_chile_4326.geometry.x.values, \n",
    "                        'size': pvs_chile_4326['POTENCIA'].values, \n",
    "                        'official_operation_start': pd.to_datetime(pvs_chile_4326['F_OPERACIO'].values), \n",
    "                        'end_time': pd.to_datetime('2018-12-30')},\n",
    "                       index=installations_list)\n",
    "    return installations_chile\n",
    "\n",
    "installations_chile = clean_installations_locations(installations_chile_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import time series and match with location\n",
    "The only link between the location data and the time series is the name of the installation. These were in most of the cases writen in different ways. The following section is a semi automatic matching of the data in both data sets. The list \"installations_with_no_match\" and the dictionary \"forced_match\" were manually constructed after several iterations of the matching attempts with the fuzzy string matching function. Only the final runing version is provide here and is can be seen they are interdependent. That is why the list and the dictionary are defined before the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the list of files with pv generation data from energía abierta for the sen \n",
    "#(should include sic and sing \n",
    "#https://www.coordinador.cl/operacion/graficos/operacion-real/generacion-real-del-sistema/?radio-formato=xlsx)\n",
    "time_series_files = Path(\"input_data/energia_abierta/*.xlsx\")\n",
    "def get_list_of_pv_files(time_series_files):\n",
    "    generation_chile_pre_sen = list(glob.glob(str(time_series_files)))\n",
    "    generation_chile_sen = Tcl().call('lsort', '-dict', generation_chile_pre_sen)\n",
    "    return generation_chile_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_chile_sen = get_list_of_pv_files(time_series_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a list of installations names that do not have a match\n",
    "installations_with_no_match = (\"SOLAR PSF PAMA\",  \n",
    "                               \"SOLAR EL PILAR - LOS AMARILLOS\", \n",
    "                               \"SOLAR LOMA LOS COLORADOS\",\n",
    "                               \"SOLAR LUNA\",\n",
    "                               \"SOLAR DONA CARMEN\",\n",
    "                               \"SOLAR EL PELICANO\", \n",
    "                               \"SOLAR PAMA\", \n",
    "                               \"SOLAR OLIVILLO\",\n",
    "                               \"SOLAR EL CHINCOL\",\n",
    "                               \"SOLAR CATAN\", \n",
    "                               \"SOLAR LAS PALOMAS\")\n",
    "#define a list of installations, which automatic matching using \n",
    "#fuzzy matching might lead to multiple installations \n",
    "#being associated to on single time series\n",
    "forced_match = {\"SOLAR LAGUNILLA\":\"PFV LAGUNILLA\", \n",
    "                \"SOLAR LALACKAMA 2\":\"LALACKAMA 2\", \n",
    "                \"SOLAR LALACKAMA\":\"LALACKAMA\",\n",
    "                \"SOLAR TAMBO REAL\":\"TAMBO REAL\",\n",
    "                \"SOLAR SAN ANDRÉS\":\"SOLAR SAN ANDRES\",\n",
    "                \"SOLAR LUZ DEL NORTE\":\"LUZ DEL NORTE\",\n",
    "                \"SOLAR PAMPA SOLAR NORTE\":\"PAMPA SOLAR NORTE\",\n",
    "                \"SOLAR PV CONEJO\":\"CONEJO SOLAR\", \n",
    "                \"SOLAR CARRERA PINTO\":\"CARRERA PINTO ETAPA I\",\n",
    "                \"SOLAR SAN PEDRO\":\"PFV SAN PEDRO\",\n",
    "                \"SOLAR LA QUINTA\":\"LA QUINTA SOLAR\",\n",
    "                \"SOLAR CERNICALO 1\":\"EL CERNICALO 1\",\n",
    "                \"SOLAR CERNICALO 2\":\"EL CERNICALO 2\",\n",
    "                \"SOLAR SAN FRANCISCO\":\"SAN FRANCISCO SOLAR\",\n",
    "                \"SOLAR TALHUEN\":\"TALHUEN\", \n",
    "                \"SOLAR ANDES\":\"ANDES SOLAR\", \n",
    "                \"SOLAR LA HUAYCA 2\":\"SPS LA HUAYCA\", \n",
    "                \"SOLAR PILOTO CARDONES\":\"PILOTO SOLAR CARDONES\",\n",
    "                \"SOLAR LUDERS\":\"PFV LUDERS\", \n",
    "                \"SOLAR TIL TIL\":\"TILTIL SOLAR\", \n",
    "                \"SOLAR PUERTO SECO\":\"PUERTO SECO SOLAR\", \n",
    "                \"SOLAR SANTIAGO\":\"SANTIAGO SOLAR\", \n",
    "                \"SOLAR URIBE\":\"URIBE SOLAR\",\n",
    "                \"SOLAR SAN FRANCISCO \":\"SAN FRANCISCO SOLAR\",\n",
    "                \"SOLAR PICA \":\"PMGD PICA PILOT\",\n",
    "                \"SOLAR SOL\":\"SOL DEL NORTE\", \n",
    "                \"SOLAR OCOA\":\"OCOA\", \n",
    "                \"SOLAR PORTEZUELO\":\"PORTEZUELO\", \n",
    "                \"SOLAR SAN FRANCISCO\":\"SAN FRANCISCO SOLAR\",\n",
    "                \"SOLAR VILLA PRAT\":\"VILLA PRAT\",\n",
    "                \"SOLAR CALAMA 1\":\"CALAMA SOLAR 1\",\n",
    "                \"SOLAR FRANCISCO\":\"FRANCISCO SOLAR\", \n",
    "                \"SOLAR RODEO\":\"RODEO\",\n",
    "                \"SOLAR SANTA LAURA\":\"SANTA LAURA\", \n",
    "                \"SOLAR SANTUARIO\":\"SANTUARIO SOLAR\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installations_matching(installations_list,matching_ratio):\n",
    "    '''creates a data frame of the time series of electricity ouput using the names of the PV installations\n",
    "    that are originally comming from the data set with the locations'''\n",
    "    date_range = pd.date_range(start='1/1/2014', end='01/01/2019', freq='H', tz='Chile/Continental')\n",
    "    date_range_m = pd.date_range(start='1/1/2014', end='31/12/2018', freq='M', tz='Chile/Continental')\n",
    "    days_all = pd.date_range(start='1/1/2014', end='31/12/2018', freq='D')\n",
    "    timeseries_installations_sen = pd.DataFrame(columns=installations_list, index=pd.to_datetime(date_range))\n",
    "    file = 0\n",
    "    day_counter = 0\n",
    "    for month in date_range_m:\n",
    "        output_chile = pd.read_excel(generation_chile_sen[file], sheet_name='Sheet', header=3)\n",
    "        for day in days_all[day_counter:]:\n",
    "            #print(day)\n",
    "            output_chile_day = (output_chile.loc[(output_chile[\"Tipo\"]==\"Solar\") &\n",
    "                                             (output_chile[\"Fecha\"]==((str(day))[:-9]))])\n",
    "            start_hour = day_counter * 24\n",
    "            stop_hour = start_hour + 24\n",
    "            #print(str(day_file)+\"  \"+str(start_hour)+\" \"+str(stop_hour))\n",
    "            #go through all installations in a day and store the hourly values in timeseries_installations_sen\n",
    "            for installations in output_chile_day.index:\n",
    "                installation = unidecode.unidecode(output_chile_day.loc[installations][\"Grupo reporte\"].upper())\n",
    "                #print(installation)\n",
    "                hourly_values = output_chile_day.loc[installations][6:30]\n",
    "                if installation in timeseries_installations_sen.columns:\n",
    "                    timeseries_installations_sen[installation][start_hour:stop_hour] = \\\n",
    "                    hourly_values\n",
    "                    #print(str(installation) + \"*\")\n",
    "                elif str('SOLAR '+str(installation)) in timeseries_installations_sen.columns:\n",
    "                    timeseries_installations_sen['SOLAR '+str(installation)][start_hour:stop_hour] = \\\n",
    "                    hourly_values\n",
    "                    #print(str(installation) + \"**\")\n",
    "                elif installation in installations_with_no_match:\n",
    "                    #print(str(installation) + \" is part of the list without a match\")\n",
    "                    pass\n",
    "                elif installation in forced_match:\n",
    "                    #print(str(installation) + \" is part of the list with forced match\")\n",
    "                    timeseries_installations_sen[forced_match[installation]][start_hour:stop_hour] = \\\n",
    "                    hourly_values\n",
    "                else:\n",
    "                    #print(installation)\n",
    "                    running_ratio = matching_ratio\n",
    "                    for installation_not_match in timeseries_installations_sen.columns:\n",
    "                        if fuzz.partial_ratio(installation,installation_not_match)> matching_ratio and \\\n",
    "                        fuzz.partial_ratio(installation,installation_not_match)> running_ratio:\n",
    "                            running_ratio = fuzz.partial_ratio(installation,installation_not_match)\n",
    "                            #print(str(fuzz.partial_ratio(installation,installation_not_match)) + \" \" + \n",
    "                                    #str(installation)+ \" \" +str(installation_not_match))\n",
    "                            timeseries_installations_sen[installation_not_match][start_hour:stop_hour] = \\\n",
    "                            hourly_values\n",
    "            day_counter += 1\n",
    "            if day in date_range_m:\n",
    "                file += 1\n",
    "                #print(str(day)+\" end of the month \"+str(file))\n",
    "                break\n",
    "    return timeseries_installations_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_installations_sen = installations_matching(installations_chile.index,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the raw data \n",
    "#timeseries_installations_sen.to_csv('intermediate_results/time_series_PV_sen_chile_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean the data for outlayers and calculate capacity factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cf_meassured_data(timeseries_installations_sen):\n",
    "    '''creates a df of capacity factor values for the meassured\n",
    "    data from the PV installations after cleaning up for outlayers'''\n",
    "    reference_pre1 = timeseries_installations_sen\n",
    "    for i in timeseries_installations_sen.columns:\n",
    "        generation_raw1 = timeseries_installations_sen[i].dropna().copy()\n",
    "        if np.sum(generation_raw1) > 0:\n",
    "            installation_size = (np.percentile(generation_raw1,99))\n",
    "            outliers_threshold = installation_size * 1.1\n",
    "            #transfrom the outlayers into nan\n",
    "            generation_raw2 = timeseries_installations_sen[i].where(timeseries_installations_sen[i] < outliers_threshold, \n",
    "                                                                    np.nan).copy()\n",
    "            #normalize by the maximum value after cleaning the outlayers\n",
    "            #reference_pre1[i] = ((generation_raw2/np.max(generation_raw2))*1000).copy()\n",
    "            reference_pre1[i] = ((generation_raw2/np.max(generation_raw2))).copy()\n",
    "            #uncomment to se examples of the outlayers cleaning\n",
    "            #print(i)\n",
    "            #print(installation_size)\n",
    "            #print(outliers_threshold)\n",
    "            #fig = plt.figure(figsize=(20,6))\n",
    "            #plt.plot(generation_raw1)\n",
    "            #plt.plot(generation_raw2)\n",
    "            #plt.show()               \n",
    "\n",
    "    ###all 0 values are transformed to non data \n",
    "    reference = reference_pre1.tz_convert('UTC').where(reference_pre1 > 0.0, np.nan).copy()\n",
    "    return reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = calculate_cf_meassured_data(timeseries_installations_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference.to_csv(Path('intermediate_results/time_series_PV_sen_chile_capacity_factors.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-py37]",
   "language": "python",
   "name": "conda-env-miniconda3-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
